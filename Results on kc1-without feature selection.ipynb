{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04f4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#importing dataset\n",
    "data = pd.read_csv('kc1_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233e3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2109 entries, 0 to 2108\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc                2109 non-null   float64\n",
      " 1   v(g)               2109 non-null   float64\n",
      " 2   ev(g)              2109 non-null   float64\n",
      " 3   iv(g)              2109 non-null   float64\n",
      " 4   n                  2109 non-null   float64\n",
      " 5   v                  2109 non-null   float64\n",
      " 6   l                  2109 non-null   float64\n",
      " 7   d                  2109 non-null   float64\n",
      " 8   i                  2109 non-null   float64\n",
      " 9   e                  2109 non-null   float64\n",
      " 10  b                  2109 non-null   float64\n",
      " 11  t                  2109 non-null   float64\n",
      " 12  lOCode             2109 non-null   int64  \n",
      " 13  lOComment          2109 non-null   int64  \n",
      " 14  lOBlank            2109 non-null   int64  \n",
      " 15  locCodeAndComment  2109 non-null   int64  \n",
      " 16  uniq_Op            2109 non-null   float64\n",
      " 17  uniq_Opnd          2109 non-null   float64\n",
      " 18  total_Op           2109 non-null   float64\n",
      " 19  total_Opnd         2109 non-null   float64\n",
      " 20  branchCount        2109 non-null   float64\n",
      " 21  defects            2109 non-null   bool   \n",
      "dtypes: bool(1), float64(17), int64(4)\n",
      "memory usage: 348.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() #informs about the data (memory usage, data types etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9c980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>927.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>23.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>21378.61</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>769.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>11436.73</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>254.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.35</td>\n",
       "      <td>27.25</td>\n",
       "      <td>2381.95</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>569.73</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.27</td>\n",
       "      <td>50.53</td>\n",
       "      <td>6423.73</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>751.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.43</td>\n",
       "      <td>48.72</td>\n",
       "      <td>11596.34</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1212.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>27.27</td>\n",
       "      <td>44.45</td>\n",
       "      <td>33061.94</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>745.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.20</td>\n",
       "      <td>45.99</td>\n",
       "      <td>12069.00</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>801.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.82</td>\n",
       "      <td>44.97</td>\n",
       "      <td>14278.39</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc  v(g)  ev(g)  iv(g)      n        v     l      d      i         e  \\\n",
       "0   1.1   1.4    1.4    1.4    1.3     1.30  1.30   1.30   1.30      1.30   \n",
       "1   1.0   1.0    1.0    1.0    1.0     1.00  1.00   1.00   1.00      1.00   \n",
       "2  83.0  11.0    1.0   11.0  171.0   927.89  0.04  23.04  40.27  21378.61   \n",
       "3  46.0   8.0    6.0    8.0  141.0   769.78  0.07  14.86  51.81  11436.73   \n",
       "4  25.0   3.0    1.0    3.0   58.0   254.75  0.11   9.35  27.25   2381.95   \n",
       "5  43.0   3.0    1.0    3.0  115.0   569.73  0.09  11.27  50.53   6423.73   \n",
       "6  48.0   6.0    1.0    6.0  149.0   751.61  0.06  15.43  48.72  11596.34   \n",
       "7  69.0  12.0    1.0   12.0  231.0  1212.27  0.04  27.27  44.45  33061.94   \n",
       "8  47.0   6.0    1.0    6.0  149.0   745.00  0.06  16.20  45.99  12069.00   \n",
       "9  48.0   7.0    1.0    7.0  155.0   801.34  0.06  17.82  44.97  14278.39   \n",
       "\n",
       "   ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0  ...       2          2        2                  2      1.2        1.2   \n",
       "1  ...       1          1        1                  1      1.0        1.0   \n",
       "2  ...      65         10        6                  0     18.0       25.0   \n",
       "3  ...      37          2        5                  0     16.0       28.0   \n",
       "4  ...      21          0        2                  0     11.0       10.0   \n",
       "5  ...      35          2        4                  0     11.0       20.0   \n",
       "6  ...      41          2        2                  0     12.0       21.0   \n",
       "7  ...      62          3        2                  0     16.0       22.0   \n",
       "8  ...      41          2        1                  0     12.0       20.0   \n",
       "9  ...      42          2        1                  0     14.0       22.0   \n",
       "\n",
       "   total_Op  total_Opnd  branchCount  defects  \n",
       "0       1.2         1.2          1.4    False  \n",
       "1       1.0         1.0          1.0     True  \n",
       "2     107.0        64.0         21.0     True  \n",
       "3      89.0        52.0         15.0     True  \n",
       "4      41.0        17.0          5.0     True  \n",
       "5      74.0        41.0          5.0     True  \n",
       "6      95.0        54.0         11.0     True  \n",
       "7     156.0        75.0         23.0     True  \n",
       "8      95.0        54.0         11.0     True  \n",
       "9      99.0        56.0         13.0     True  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf01770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:28]\n",
    "y=data.iloc[:,-1]\n",
    "#preprocessing \n",
    "#changing categorical into numerical values\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_y=preprocessing.LabelEncoder()\n",
    "y=encoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf655522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a0548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 233\n",
      "Before OverSampling, counts of label '0': 1243 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of Labels in the Training Set\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9e02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Over Sampling, counts of label '1': 1243\n",
      "After Over Sampling, counts of label '0': 1243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over = SMOTE(random_state = 1)\n",
    "X_train2, y_train2 = over.fit_resample(X_train, y_train.ravel())\n",
    "print(\"After Over Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Over Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31985bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Under Sampling, counts of label '1': 233\n",
      "After Under Sampling, counts of label '0': 233\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(random_state = 1)\n",
    "X_train2, y_train2 = under.fit_resample(X_train, y_train.ravel())\n",
    "  \n",
    "print(\"After Under Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Under Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f5c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce56a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "accuracy_score 1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score_score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with MLP\n",
    "classifier1=MLPClassifier(activation = 'tanh',max_iter=1000,alpha= 0.0001)\n",
    "classifier1.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_mlp=classifier1.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_mlp)\n",
    "accuracy_score_mlp=metrics.accuracy_score(y_test,y_pred_mlp)\n",
    "print('MLPClassifier')\n",
    "print(\"accuracy_score {:.4f}\".format(accuracy_score_mlp))\n",
    "\n",
    "#for precision\n",
    "precision_mlp=metrics.precision_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_mlp))\n",
    "\n",
    "#for recall\n",
    "recall_mlp=metrics.recall_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_mlp))\n",
    "\n",
    "#for f-score\n",
    "fscore_mlp=metrics.f1_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"f-score_score={:.4f}\".format(fscore_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f319d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with naive bayes\n",
    "classifier2=GaussianNB()\n",
    "classifier2.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_nb=classifier2.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_nb)\n",
    "accuracy_score_nb=metrics.accuracy_score(y_test,y_pred_nb)\n",
    "print('Naive Bayes Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_nb))\n",
    "\n",
    "#for precision\n",
    "precision_nb=metrics.precision_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_nb))\n",
    "\n",
    "#for  recall\n",
    "recall_nb=metrics.recall_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_nb))\n",
    "\n",
    "#for  f-score\n",
    "fscore_nb=metrics.f1_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac29eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with Deecision Tree\n",
    "classifier3=DecisionTreeClassifier()\n",
    "classifier3.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_DT=classifier3.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_DT)\n",
    "accuracy_score_DT=metrics.accuracy_score(y_test,y_pred_DT)\n",
    "print('Decision Tree Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_DT))\n",
    "\n",
    "#for precision\n",
    "precision_DT=metrics.precision_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_DT))\n",
    "\n",
    "#for  recall\n",
    "recall_DT=metrics.recall_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_DT))\n",
    "\n",
    "#for f-score\n",
    "fscore_DT=metrics.f1_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26178ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector Classifier\n",
      "accuracy_score0.9700\n",
      "precision_score=0.9751\n",
      "recall_score=0.9700\n",
      "f-score=0.9711\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with svm\n",
    "from sklearn.svm import SVC\n",
    "classifier4=SVC(probability=True,C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "classifier4.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_svm=classifier4.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_svm)\n",
    "accuracy_score_svm=metrics.accuracy_score(y_test,y_pred_svm)\n",
    "print('Support vector Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_svm))\n",
    "\n",
    "#for precision\n",
    "precision_svm=metrics.precision_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_svm))\n",
    "\n",
    "#for recall\n",
    "recall_svm=metrics.recall_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_svm))\n",
    "\n",
    "#for f-score\n",
    "fscore_svm=metrics.f1_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3c238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "accuracy_score0.9731\n",
      "precision_score=0.9766\n",
      "recall_score=0.9731\n",
      "f-score=0.9740\n"
     ]
    }
   ],
   "source": [
    "#fitting model with KNeighborsClassifier\n",
    "classifier5=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier5.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_knn=classifier5.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_knn)\n",
    "accuracy_score_knn=metrics.accuracy_score(y_test,y_pred_knn)\n",
    "print('KNeighborsClassifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_knn))\n",
    "\n",
    "#for precision\n",
    "precision_knn=metrics.precision_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_knn))\n",
    "\n",
    "#for recall\n",
    "recall_knn=metrics.recall_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_knn))\n",
    "\n",
    "#for f-score\n",
    "fscore_knn=metrics.f1_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ae7407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with RandomForest\n",
    "classifier6=RandomForestClassifier()\n",
    "classifier6.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_rf=classifier6.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_rf)\n",
    "accuracy_score_rf=metrics.accuracy_score(y_test,y_pred_rf)\n",
    "print('RandomForest')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_rf))\n",
    "\n",
    "#for precision\n",
    "precision_rf=metrics.precision_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_rf))\n",
    "\n",
    "#for recall\n",
    "recall_rf=metrics.recall_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_rf))\n",
    "\n",
    "#for f-score\n",
    "fscore_rf=metrics.f1_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11bac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with LogisticRegression\n",
    "classifier7=LogisticRegression()\n",
    "classifier7.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_lr=classifier7.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_lr)\n",
    "accuracy_score_lr=metrics.accuracy_score(y_test,y_pred_lr)\n",
    "print('LogisticRegression')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_lr))\n",
    "\n",
    "#for precision\n",
    "precision_lr=metrics.precision_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_lr))\n",
    "\n",
    "#for recall\n",
    "recall_lr=metrics.recall_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_lr))\n",
    "\n",
    "#for f-score\n",
    "fscore_lr=metrics.f1_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "accuracy_score=1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with AdaBoostClassifier\n",
    "classifier8=AdaBoostClassifier()\n",
    "classifier8.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_AB=classifier8.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_AB)\n",
    "accuracy_score_AB=metrics.accuracy_score(y_test,y_pred_AB)\n",
    "print('GradientBoosting')\n",
    "print(\"accuracy_score={:.4f}\".format(accuracy_score_AB))\n",
    "\n",
    "#for precision\n",
    "precision_AB=metrics.precision_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_AB))\n",
    "\n",
    "#for recall\n",
    "recall_AB=metrics.recall_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_AB))\n",
    "\n",
    "#for f-score\n",
    "fscore_AB=metrics.f1_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0ab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising plots\n",
    "accuracy=np.array([accuracy_score_mlp,accuracy_score_nb,accuracy_score_DT,accuracy_score_svm,accuracy_score_knn,accuracy_score_rf,accuracy_score_lr,accuracy_score_AB])\n",
    "precision=np.array([precision_mlp,precision_nb,precision_DT,precision_svm,precision_knn,precision_rf,precision_lr,precision_AB])\n",
    "recall=np.array([recall_mlp,recall_nb,recall_DT,recall_svm,recall_knn,recall_rf,recall_lr,recall_AB])\n",
    "fscore=np.array([fscore_knn,fscore_nb,fscore_DT,fscore_svm,fscore_knn,fscore_rf,fscore_lr,fscore_AB])\n",
    "x=np.arange(len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfe5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "bar_width=0.15\n",
    "plt.bar(x,accuracy,width=bar_width,color='purple',zorder=2)\n",
    "plt.bar(x+bar_width,precision,width=bar_width,color='orange',zorder=2)\n",
    "plt.bar(x+bar_width*2,recall,width=bar_width,color='red',zorder=2)\n",
    "plt.bar(x+bar_width*3,fscore,width=bar_width,color='green',zorder=2)\n",
    "\n",
    "\n",
    "#for labeling part\n",
    "plt.xticks(x+bar_width*1.5,['MLP','NB',\"DT\",\"SVC\",\"KNN\",\"RF\",\"LR\",\"AB\"])\n",
    "plt.title('Results on kc1 dataset without feature selection method')\n",
    "\n",
    "#for making patches\n",
    "green=mpatches.Patch(color='purple',label='accuracy')\n",
    "orange=mpatches.Patch(color='orange',label='precision')\n",
    "red=mpatches.Patch(color='red',label='recall')\n",
    "purple=mpatches.Patch(color='green',label='fscore')\n",
    "plt.legend(handles=[purple,orange,red,green])\n",
    "plt.ylim(0,1.5)\n",
    "\n",
    "#grid\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
