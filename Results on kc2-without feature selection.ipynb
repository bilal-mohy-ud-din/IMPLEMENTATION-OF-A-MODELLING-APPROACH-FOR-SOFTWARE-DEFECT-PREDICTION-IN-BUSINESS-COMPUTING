{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04f4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#importing dataset\n",
    "data = pd.read_csv('kc2_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233e3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc                522 non-null    float64\n",
      " 1   v(g)               522 non-null    float64\n",
      " 2   ev(g)              522 non-null    float64\n",
      " 3   iv(g)              522 non-null    float64\n",
      " 4   n                  522 non-null    float64\n",
      " 5   v                  522 non-null    float64\n",
      " 6   l                  522 non-null    float64\n",
      " 7   d                  522 non-null    float64\n",
      " 8   i                  522 non-null    float64\n",
      " 9   e                  522 non-null    float64\n",
      " 10  b                  522 non-null    float64\n",
      " 11  t                  522 non-null    float64\n",
      " 12  lOCode             522 non-null    int64  \n",
      " 13  lOComment          522 non-null    int64  \n",
      " 14  lOBlank            522 non-null    int64  \n",
      " 15  locCodeAndComment  522 non-null    int64  \n",
      " 16  uniq_Op            522 non-null    float64\n",
      " 17  uniq_Opnd          522 non-null    float64\n",
      " 18  total_Op           522 non-null    float64\n",
      " 19  total_Opnd         522 non-null    float64\n",
      " 20  branchCount        522 non-null    float64\n",
      " 21  defects            522 non-null    bool   \n",
      "dtypes: bool(1), float64(17), int64(4)\n",
      "memory usage: 86.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() #informs about the data (memory usage, data types etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9c980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>8411.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.53</td>\n",
       "      <td>81.24</td>\n",
       "      <td>870848.58</td>\n",
       "      <td>...</td>\n",
       "      <td>359</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>3732.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>39.82</td>\n",
       "      <td>93.74</td>\n",
       "      <td>148644.06</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3123.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.48</td>\n",
       "      <td>105.96</td>\n",
       "      <td>92103.07</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>163.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>2714.77</td>\n",
       "      <td>0.03</td>\n",
       "      <td>32.25</td>\n",
       "      <td>84.14</td>\n",
       "      <td>87589.65</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>152.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>2629.78</td>\n",
       "      <td>0.03</td>\n",
       "      <td>31.68</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83311.56</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.79</td>\n",
       "      <td>15.21</td>\n",
       "      <td>509.14</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.53</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.00</td>\n",
       "      <td>9.22</td>\n",
       "      <td>451.71</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc  v(g)  ev(g)  iv(g)       n        v     l       d       i  \\\n",
       "0    1.1   1.4    1.4    1.4     1.3     1.30  1.30    1.30    1.30   \n",
       "1    1.0   1.0    1.0    1.0     1.0     1.00  1.00    1.00    1.00   \n",
       "2  415.0  59.0   50.0   51.0  1159.0  8411.31  0.01  103.53   81.24   \n",
       "3  230.0  33.0   10.0   16.0   575.0  3732.82  0.03   39.82   93.74   \n",
       "4  175.0  26.0   12.0   13.0   500.0  3123.96  0.03   29.48  105.96   \n",
       "5  163.0  16.0   13.0   11.0   440.0  2714.77  0.03   32.25   84.14   \n",
       "6  152.0  11.0    6.0   11.0   432.0  2629.78  0.03   31.68   83.01   \n",
       "7    3.0   1.0    1.0    1.0     1.0     0.00  0.00    0.00    0.00   \n",
       "8   14.0   2.0    1.0    2.0    22.0    88.00  0.17    5.79   15.21   \n",
       "9   10.0   2.0    1.0    2.0    18.0    64.53  0.14    7.00    9.22   \n",
       "\n",
       "           e  ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  \\\n",
       "0       1.30  ...       2          2        2                  2      1.2   \n",
       "1       1.00  ...       1          1        1                  1      1.0   \n",
       "2  870848.58  ...     359         35        9                 10     47.0   \n",
       "3  148644.06  ...     174         15       34                  5     23.0   \n",
       "4   92103.07  ...     142          7       19                  4     18.0   \n",
       "5   87589.65  ...     139          2       20                  0     19.0   \n",
       "6   83311.56  ...     114         18       17                  0     18.0   \n",
       "7       0.00  ...       1          0        0                  0      1.0   \n",
       "8     509.14  ...       8          0        1                  0      9.0   \n",
       "9     451.71  ...       8          0        0                  0      8.0   \n",
       "\n",
       "   uniq_Opnd  total_Op  total_Opnd  branchCount  defects  \n",
       "0        1.2       1.2         1.2          1.4    False  \n",
       "1        1.0       1.0         1.0          1.0     True  \n",
       "2      106.0     692.0       467.0        106.0     True  \n",
       "3       67.0     343.0       232.0         65.0     True  \n",
       "4       58.0     310.0       190.0         51.0     True  \n",
       "5       53.0     260.0       180.0         31.0     True  \n",
       "6       50.0     256.0       176.0         21.0     True  \n",
       "7        0.0       1.0         0.0          1.0    False  \n",
       "8        7.0      13.0         9.0          3.0    False  \n",
       "9        4.0      11.0         7.0          3.0    False  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf01770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:28]\n",
    "y=data.iloc[:,-1]\n",
    "#preprocessing \n",
    "#changing categorical into numerical values\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_y=preprocessing.LabelEncoder()\n",
    "y=encoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf655522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a0548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 80\n",
      "Before OverSampling, counts of label '0': 285 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of Labels in the Training Set\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9e02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Over Sampling, counts of label '1': 285\n",
      "After Over Sampling, counts of label '0': 285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over = SMOTE(random_state = 1)\n",
    "X_train2, y_train2 = over.fit_resample(X_train, y_train.ravel())\n",
    "print(\"After Over Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Over Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31985bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Under Sampling, counts of label '1': 80\n",
      "After Under Sampling, counts of label '0': 80\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(random_state = 1)\n",
    "X_train2, y_train2 = under.fit_resample(X_train, y_train.ravel())\n",
    "  \n",
    "print(\"After Under Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Under Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f5c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce56a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "accuracy_score 0.9936\n",
      "precision_score=0.9939\n",
      "recall_score=0.9936\n",
      "f-score_score=0.9937\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with MLP\n",
    "classifier1=MLPClassifier(activation = 'tanh',max_iter=1000,alpha= 0.0001)\n",
    "classifier1.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_mlp=classifier1.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_mlp)\n",
    "accuracy_score_mlp=metrics.accuracy_score(y_test,y_pred_mlp)\n",
    "print('MLPClassifier')\n",
    "print(\"accuracy_score {:.4f}\".format(accuracy_score_mlp))\n",
    "\n",
    "#for precision\n",
    "precision_mlp=metrics.precision_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_mlp))\n",
    "\n",
    "#for recall\n",
    "recall_mlp=metrics.recall_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_mlp))\n",
    "\n",
    "#for f-score\n",
    "fscore_mlp=metrics.f1_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"f-score_score={:.4f}\".format(fscore_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f319d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with naive bayes\n",
    "classifier2=GaussianNB()\n",
    "classifier2.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_nb=classifier2.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_nb)\n",
    "accuracy_score_nb=metrics.accuracy_score(y_test,y_pred_nb)\n",
    "print('Naive Bayes Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_nb))\n",
    "\n",
    "#for precision\n",
    "precision_nb=metrics.precision_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_nb))\n",
    "\n",
    "#for  recall\n",
    "recall_nb=metrics.recall_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_nb))\n",
    "\n",
    "#for  f-score\n",
    "fscore_nb=metrics.f1_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac29eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with Deecision Tree\n",
    "classifier3=DecisionTreeClassifier()\n",
    "classifier3.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_DT=classifier3.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_DT)\n",
    "accuracy_score_DT=metrics.accuracy_score(y_test,y_pred_DT)\n",
    "print('Decision Tree Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_DT))\n",
    "\n",
    "#for precision\n",
    "precision_DT=metrics.precision_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_DT))\n",
    "\n",
    "#for  recall\n",
    "recall_DT=metrics.recall_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_DT))\n",
    "\n",
    "#for f-score\n",
    "fscore_DT=metrics.f1_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26178ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector Classifier\n",
      "accuracy_score0.9809\n",
      "precision_score=0.9828\n",
      "recall_score=0.9809\n",
      "f-score=0.9813\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with svm\n",
    "from sklearn.svm import SVC\n",
    "classifier4=SVC(probability=True,C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "classifier4.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_svm=classifier4.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_svm)\n",
    "accuracy_score_svm=metrics.accuracy_score(y_test,y_pred_svm)\n",
    "print('Support vector Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_svm))\n",
    "\n",
    "#for precision\n",
    "precision_svm=metrics.precision_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_svm))\n",
    "\n",
    "#for recall\n",
    "recall_svm=metrics.recall_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_svm))\n",
    "\n",
    "#for f-score\n",
    "fscore_svm=metrics.f1_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3c238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "accuracy_score0.9809\n",
      "precision_score=0.9828\n",
      "recall_score=0.9809\n",
      "f-score=0.9813\n"
     ]
    }
   ],
   "source": [
    "#fitting model with KNeighborsClassifier\n",
    "classifier5=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier5.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_knn=classifier5.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_knn)\n",
    "accuracy_score_knn=metrics.accuracy_score(y_test,y_pred_knn)\n",
    "print('KNeighborsClassifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_knn))\n",
    "\n",
    "#for precision\n",
    "precision_knn=metrics.precision_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_knn))\n",
    "\n",
    "#for recall\n",
    "recall_knn=metrics.recall_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_knn))\n",
    "\n",
    "#for f-score\n",
    "fscore_knn=metrics.f1_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ae7407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "accuracy_score0.9809\n",
      "precision_score=0.9828\n",
      "recall_score=0.9809\n",
      "f-score=0.9813\n"
     ]
    }
   ],
   "source": [
    "#fitting model with RandomForest\n",
    "classifier6=RandomForestClassifier()\n",
    "classifier6.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_rf=classifier6.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_rf)\n",
    "accuracy_score_rf=metrics.accuracy_score(y_test,y_pred_rf)\n",
    "print('RandomForest')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_rf))\n",
    "\n",
    "#for precision\n",
    "precision_rf=metrics.precision_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_rf))\n",
    "\n",
    "#for recall\n",
    "recall_rf=metrics.recall_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_rf))\n",
    "\n",
    "#for f-score\n",
    "fscore_rf=metrics.f1_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11bac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with LogisticRegression\n",
    "classifier7=LogisticRegression()\n",
    "classifier7.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_lr=classifier7.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_lr)\n",
    "accuracy_score_lr=metrics.accuracy_score(y_test,y_pred_lr)\n",
    "print('LogisticRegression')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_lr))\n",
    "\n",
    "#for precision\n",
    "precision_lr=metrics.precision_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_lr))\n",
    "\n",
    "#for recall\n",
    "recall_lr=metrics.recall_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_lr))\n",
    "\n",
    "#for f-score\n",
    "fscore_lr=metrics.f1_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "accuracy_score=1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with AdaBoostClassifier\n",
    "classifier8=AdaBoostClassifier()\n",
    "classifier8.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_AB=classifier8.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_AB)\n",
    "accuracy_score_AB=metrics.accuracy_score(y_test,y_pred_AB)\n",
    "print('GradientBoosting')\n",
    "print(\"accuracy_score={:.4f}\".format(accuracy_score_AB))\n",
    "\n",
    "#for precision\n",
    "precision_AB=metrics.precision_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_AB))\n",
    "\n",
    "#for recall\n",
    "recall_AB=metrics.recall_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_AB))\n",
    "\n",
    "#for f-score\n",
    "fscore_AB=metrics.f1_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0ab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising plots\n",
    "accuracy=np.array([accuracy_score_mlp,accuracy_score_nb,accuracy_score_DT,accuracy_score_svm,accuracy_score_knn,accuracy_score_rf,accuracy_score_lr,accuracy_score_AB])\n",
    "precision=np.array([precision_mlp,precision_nb,precision_DT,precision_svm,precision_knn,precision_rf,precision_lr,precision_AB])\n",
    "recall=np.array([recall_mlp,recall_nb,recall_DT,recall_svm,recall_knn,recall_rf,recall_lr,recall_AB])\n",
    "fscore=np.array([fscore_knn,fscore_nb,fscore_DT,fscore_svm,fscore_knn,fscore_rf,fscore_lr,fscore_AB])\n",
    "x=np.arange(len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfe5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAApMklEQVR4nO3deXxU9b3/8dfHsEQgIouNYhCw9SKyhGAQEJW4UMEFrJWLXFxALaUtWmutUm0rLtdWr7YWL9ZSi0ituOC1pS0tlpaAVlGhRVBZRESJdUFADGJk+/z+OCdxGGYyk2RmEs7v/Xw88sicc77n+/2c7TPnfOfMGXN3REQkWg5q7ABERCTzlNxFRCJIyV1EJIKU3EVEIkjJXUQkgpTcRUQi6P+L5G5m5WZ2RWPHEcvMZprZbTluc5yZPZvLNnPJzLab2dG1TN9gZmfkMqaYtgvNbLGZVZrZ3Y0RQ66Z2RQzezgL9d5gZg9kut5sy+T6SOdYznlyDw+wT8MD8b0wybXJYfsHbIIzs/8ws9+b2SYz22Jm882se5baysqBmc123L2Nu68P683Zm2ea+9QE4EPgEHf/bgPby/mJQWMxszIzq4gd5+63u3uTOlmLlyjuXGusM/dz3b0N0BcoAb7fSHEcaA4F5gLdgULgReD3jRmQpK0L8Jo3gW8Nmlmzxo5BcsDdc/oHbADOiBm+E/hTzPBA4DngI+BloCxm2jhgPVAJvAmMDcdPAR6OKdcVcKBZOFwOXAH0AKqAPcB24KNw+lnAa2G97wDXJon9IOAHwFvAB8AsoG1cm5cCbxOcpd1Yy3qYCdwWvi4AFgJTAQMOBu4O29kGPAscnKCO9mGbHZK00YHgzeBjgjeCW4FnY6b/HNgYTl8GnByOHwbsBHaF6+nlcPx4YFW4ntYDX4+pqyPwx3C7bQGeAQ4Kp3UCngQ2hdvtqtraiVuG8cAfYoZfB56IGd4I9A1fO/AlgrPkXWHd26vnJ9j3rgVWhOv1MSA/pq6vAevC+OcCnRLtT+nsUwm2dWw8ZxDsS5OBN4DNwONA+5h5ngDeC+NcDPQMxydbNge+lGT/KgMqgOvDOn+Tqv24+Ou8bZMcl7Ud2+2BB4F/A1uB3wGtgU+BveGybg/bi693BPBqWG850CMu3yTd5nHLOQ74B/CzsK71wInh+I0Ex/ylMeVbAncRHO/vA/cTHLu1xf04Qd6oDGMujamvRxj/R+G0EekeywmXJxcJPW4FbiBM7kARsBL4eTh8ZLijnRXufEPD4cPCFfYx0D0sewSf7/DxG7srCZJ7zAZ8Ni6md/k8sbUD+iWJ/TKCg/9ooA3wf8Bv4tr8VbiBi4HPYne0BAf8beFGe5HwQAynTQtjPhLIC3ewlgnqOA94t5Z1/Wi4M7UGehG8ccUm94vC9psB3yU48PMTrdNw3NnAFwnegIYAO6rXFfBjgp27efh3cljuIII3jh8BLcJ1tx44M1k7cW0eTbCzH0RwgLwFVMRM28rniaYmwRGT3OL2vRfDetoTvFFNDKedRvCG3I/goL0XWJxof0pnn0q2vWOGvw0sITgGWgK/BGbH7WsF4bR7gOXJ6opf9vgyBMl9N3BHWN/BqdqPq7vB25Zaju1w+p8IEm+7sI0hMbFXxMUTW+9/AJ+E9TUHriM4Rluk2uYJlnNcuJ7GExx3txEk7mnhOvoyQVJuE5b/GUHCbR9uqz8AP04Rd1W4DvLC9boknNY8jPuGcF2eFrZVne9qPZYTLk9DEnV9/sKVvT0M3IG/AYeG064nTJYx5ecTnA23JjjIv0rcWSwNT+5vA18n6A+tLfa/Ad+MGe5OcBbVLKbNopjpLwIX1nKwzwBeAb4XM/4ggnf94hSxFIUbeEyS6XlhbMfGjLu9th2CIFEWJ1qnScr/Dvh2+PoWgi6iL8WVGQC8HTfu+8CDdWhnI0HSvRCYHq7XYwkOwrkx5dJJ7hfFDN8J3B++/jVwZ8y0NuH66xq/P6WzTyXZ3rHJfRVweszwEdX7UoJ5Dw3bb1vLsqVK7jvZ9yqlLu03eNtS+7F9BMFZbrsEbZdRe3L/IfB43PHzDuFVQW3bPEFb44DXY4Z7h+u1MGbcZoLuZCN4U/lizLRBwJsp4l4QM3wc8Gn4+mSCk6uDYqbPDuep87Hs7o3W536euxcQrIBjCS77IOiXHGVmH1X/AScBR7j7J8BoYCLwrpn9ycyOzVA8XyV4N33LzBaZ2aAk5arPHKu9RZDYC2PGvRfzegdBkkjmbIKzqPtjxnUE8gkulxMys8OAp4H73H12kmKHhbFtjIs3tp5rzWyVmW0L13VbPt8WidodbmZLwg9zPyJYZ9Xl/4fgzONpM1tvZpPD8V2ATnHb9Ab2XWepLCLYV04JX5cTXDkMCYfrItn22Wfbuvt2ggP5yDrWn64uwFMx62QVQddOoZnlmdlPzOwNM/uYIEFBLdsmDZvcvSqd9hPMm4ltm/TYBjoDW9x9az2WK3677SXY52O3W12OyfdjXn8a1hk/rg3B8dUKWBazPH8Jx9cmPpb88DOQTsDGMP5qb4XLkfJYTqRRb4V090UEZxh3haM2Ery7Hxrz19rdfxKWn+/uQwl2iNUEXSAQvIO2iqn68NqaTRDHS+4+EvgCwdno40nm/TfBTlrtKILLuPcTF0/pVwQ7xDwzax2O+5Dg0u2LiWYws3YEiX2uu/93LXVvCmPrHBdvdT0nE1zC/ifBGdOhBH2SFhbZZz2ZWUuCvtW7CM5kDgXmVZd390p3/667H03QB3qNmZ1OsE3fjNumBe5+VqJ2kqhO7ieHrxeROrmnU2+sfbZtuD06EJwFfhKOTraP1bUtCNbL8Lj1ku/u7wD/BYwk6JtvS3DlAEm2TWhHLfElmqe29vedsf7bNr69ZMf2RqC9mR2aYL5U6zZ+uxnBPr/fcmTYhwSJvmfM8rT14EYRqN/+19nMYnPyUQTLUeuxnExTuM/9HmComRUDDwPnmtmZ4dlLfnhLUVF4n/DI8KD7jKBrp/pdbjlwipkdZWZtqf3um/eBIjNrAWBmLcxsrJm1dfddBP36e5PMOxv4jpl1C2/fvB14zN13N2D5JwFrgD+Y2cHhO/cM4Kdm1ilcD4PMrKWZHUJwKfsPd59cW6XuvofgM4EpZtbKzI4juASuVkCww2wCmpnZj4BDYqa/D3SN2dlaEPQ7bgJ2m9lwgj5IAMzsHDP7UnhwbSM4C9xL0IVSaWbXm9nB4fL0MrP+SdpJZBFwKkF3XAXBB3rDCJLvv5LM8z5BH3C6ZgPjzaxv+EZ2O/CCu29w900EB9lFYfyXse+b7z77VJruB/7bzLpAcDVmZiPDaQUE+/hmgoR9exrLthz4rzC+YQRvfPVtfx8N2Laxkh7b7v4u8GfgPjNrZ2bNzeyUmGXtEB7XiTwOnG1mp5tZc4LPjj4j+OA2a8Lj9FfAz8zsCwBmdqSZnZlm3PFeIHiDvi5c/jLgXODRNI7lhBo9uYcHzizgR+6+keCM5QaCJLIR+B5BnAcB1xC8w20h2Hm/EdbxV4IPY1YQfMDzx1qa/DvBJ9HvmdmH4biLgQ3hJfBEYGySeWcQ3GmwmODOgCrgyjovdAwPOtAmENzN8Hszyyf4dH8l8BLBst5BsPxfAfoTJKHtMX/J3sUnEVxCvkdwhfRgzLT5BFcNawku8arY97LvifD/ZjP7p7tXAlcRHExbCc4u58aUPwZYQPCm+zxBl9HCcMc8h6Cf8k2CM54HCM5I92snyTpaG9b7TDj8McEHd/8I60/k18Bx4SXz75KUiW1jAUH/7ZMEH7B/kaCPv9rXCPbFzUBP9k0eifapVH5OsP6eNrNKgg83B4TTZhFsk3cI7uJaksayfZsgGXxEsP/+jtrV1n68+m7bGimObQiOwV0EV+QfAFeH860meONdHy5vp7h61xDcGHBv2P65BLda70yx/JlwPUF31ZIwdywg+BwuZdzxwnjPBYYTLMd9wCVhPVD7sZyQhZ3zIiISIY1+5i4iIpmn5C4iEkFK7iIiEaTkLiISQY32AKGOHTt6165dG6t5EZED0rJlyz5091Rflmq85N61a1eWLl3aWM2LiByQzCzlt1NB3TIiIpGk5C4iEkFK7iIiEaRfZBGRrNi1axcVFRVUVVWlLiz7yc/Pp6ioiObNm9drfiV3EcmKiooKCgoK6Nq1K8EzxyRd7s7mzZupqKigW7du9apD3TIikhVVVVV06NBBib0ezIwOHTo06KpHyV1EskaJvf4auu6U3EVEIkh97iKSE4ffdTjvf1LfHy3bX2HrQt679r1ay0ydOpVf/OIX9OvXj9/+9rcZa/tAoOQuIjmRycSebn333XcfCxYsoKioKKNt7969m2bNmnb6TNktY2YzzOwDM3slRbn+ZrbbzC7IXHgiIvUzceJE1q9fz/Dhw7n55pvp27cvffv2paSkhMrKSgDuuOMOevfuTXFxMZMnB79cuXz5cgYOHEifPn34yle+wtatwe92l5WVcfXVV1NaWsrPf/5zli1bxpAhQzj++OM588wzeffddxttWRNJp899JsHvVSZlZnkEPwX3dAZiEhFpsPvvv59OnTqxcOFCli5dyrRp01i+fDnPPPMMBx98MH/+85/5/e9/zwsvvMDLL7/MddddB8All1zCHXfcwYoVK+jduzc333xzTZ07d+5k6dKlXHXVVVx55ZXMmTOHZcuWcdlll3HjjTc21qImlPK6wt0Xm1nXFMWuJPjtyUQ/jCsi0qgGDx7MNddcw9ixYzn//PMpKipiwYIFjB8/nlatWgHQvn17tm3bxkcffcSQIcHvi1966aWMGjWqpp7Ro0cDsGbNGl555RWGDh0KwJ49ezjiiCNyvFS1a3CnkZkdSfDDzaeSIrmb2QSCH4OmsLCQ8vLyhjYvIk1U27Zta7o/siVV/e7O9u3b+da3vkVZWRlPP/00J554Ik899RQ7d+6kqqpqnzoqKytx95px27dvZ+/evVRWVrJnz56aMtu3b+fYY4/lb3/7W53iqauqqqp658lMfCJwD3C9u+9NdV+mu08HpgOUlpZ6WVlZBpoXkaZo1apVFBQUZLWNVPWbGW3atOGDDz5g4MCBDBw4kBUrVrBx40bOPvtsbrnlFi6//HJatWrFli1bKCoqon379ixfvpyTTz6Zp556ilNPPZWCggLy8vJo3bo1BQUF9OvXjy1btvDKK68waNAgdu3axdq1a+nZs2dGly8/P5+SkpJ6zZuJ5F4KPBom9o7AWWa2291/l4G6RSQiClsXZvxWyHTdc889LFy4kIMOOoiePXsyfPhwWrZsyfLlyyktLaVFixacddZZ3H777Tz00ENMnDiRHTt2cPTRR/Pggw/uV1+LFi2YM2cOV111Fdu2bWP37t1cffXVGU/uDWHunrpQ0Of+R3fvlaLczLDcnFR1lpaWun6sQyS6Vq1aRY8ePRo7jANaonVoZsvcvTTVvCnP3M1sNlAGdDSzCuAmoDmAu99fn4BFRCS70rlbZky6lbn7uAZFIyIiGaFny4iIRJCSu4hIBCm5i4hEkJK7iEgENe3HmolIdPzf4VCVwSdD5hfC+bU/8jcbli5dyqxZs5g6dWrC6f/+97+56qqrmDMn5R3hWaXkLiK5kcnEnsH69uzZQ15eXtrlS0tLKS1Nfpt5p06dGj2xg7plRCTCNmzYwLHHHsvYsWPp0aMHF1xwATt27KBr165cf/319OvXjyeeeIKnn36aQYMG0a9fP0aNGsX27dsBeOmllzjxxBMpLi7mhBNOoLKykvLycs455xwAFi1atN+jhDds2ECvXsH3Pauqqhg/fjy9e/empKSEhQsXAjBz5kzOP/98hg0bxjHHHFPzRMpM0pm7iETamjVr+PWvf83gwYO57LLLuO+++wDo0KED//znP/nwww85//zzWbBgAa1bt+aOO+7gpz/9KZMnT2b06NE89thj9O/fn48//piDDz54n7rvuusupk2bxuDBg9m+fTv5+fn7TJ82bRpmxsqVK1m9ejVf/vKXWbt2LRA8N/5f//oXLVu2pHv37lx55ZV07tw5Y8utM3cRibTOnTszePBgAC666CKeffZZ4PPH9y5ZsoTXXnuNwYMH07dvXx566CHeeust1qxZwxFHHEH//sHDbg855JD9fn2p+lHCU6dO5aOPPtpv+rPPPstFF10EwLHHHkuXLl1qkvvpp59O27Ztyc/P57jjjuOtt97K6HLrzF1EIi3+abXVw61btwaCxwIPHTqU2bNn71Nu5cqVKeuePHkyZ599NvPmzWPw4MHMnz9/v7P3ZFq2bFnzOi8vj927d6c1X7p05i4ikfb222/z/PPPA/DII49w0kkn7TN94MCB/OMf/2DdunUAfPLJJ6xdu5bu3bvz7rvv8tJLLwHBs9rjE/Abb7xB7969uf766+nfvz+rV6/eZ/rJJ59c88Pca9eu5e2336Z79+5ZWc54Su4ikhv56T+iN5P1de/enWnTptGjRw+2bt3KN77xjX2mH3bYYcycOZMxY8bQp08fBg0axOrVq2nRogWPPfYYV155JcXFxQwdOpSqqqp95r3nnnvo1asXffr0oXnz5gwfPnyf6d/85jfZu3cvvXv3ZvTo0cycOXOfM/ZsSuuRv9mgR/6KRFtTeOTvhg0bOOecc3jllVcaNY76asgjf3XmLiISQUruIhJZXbt2PWDP2htKyV1EJIKU3EVEIkjJXUQkgpTcRUQiSMldRHLj8MPBLHN/hx/eKIsxc+ZMJk2aBMCUKVO46667GiWOVFImdzObYWYfmFnCj5zNbKyZrTCzlWb2nJkVZz5METngvZ/hR/7WsT53Z+/evZmNoQlL58x9JjCslulvAkPcvTdwKzA9A3GJiDTYhg0b6N69O5dccgm9evXi1ltvpX///vTp04ebbrqpptysWbPo06cPxcXFXHzxxQD84Q9/YMCAAZSUlHDGGWfwfqbfnLIs5YPD3H2xmXWtZfpzMYNLgKIMxCUikhGvv/46Dz30EB9//DFz5szhxRdfxN0ZMWIEixcvpkOHDtx2220899xzdOzYkS1btgBw0kknsWTJEsyMBx54gDvvvJO77767kZcmfZl+KuTlwJ+TTTSzCcAEgMLCQsrLyzPcvIg0FW3btqWysrJmuCALbcTWn8j27ds56qij6NmzJzfeeCPz58+nuLi4ZtrKlSvZsWMHI0eOpGXLllRWVtK8eXMqKytZs2YNN9xwA++//z47d+6kS5cuVFZWUlVVxc6dO6msrOSzzz6rKZ8NVVVV9c6TGUvuZnYqQXI/KVkZd59O2G1TWlrqZWVlmWpeRJqYVatWUVCQjZT+uVT1t2nThjZt2lBQUEDz5s254YYb+PrXv75PmXvvvZcWLVrsV9fkyZO55pprGDFiBOXl5UyZMoWCggLy8/Nryrds2ZKWLVtmbTnz8/MpKSmp17wZuVvGzPoADwAj3X1zJuoUEcmkM888kxkzZtT8hN4777zDBx98wGmnncYTTzzB5s1B6qrultm2bRtHHnkkAA899FDjBN0ADT5zN7OjgP8DLnb3tQ0PSUQiqbAws3fMFNbtEcJf/vKXWbVqFYMGDQKCs/qHH364pstmyJAh5OXlUVJSwsyZM5kyZQqjRo2iXbt2nHbaabz55puZiz0HUj7y18xmA2VAR+B94CagOYC7329mDwBfBap/I2p3Oo+j1CN/RaKtKTzy90DXkEf+pnO3zJgU068ArkhVj4iI5I6+oSoiEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBmX78gIhIQncdfhefvP9JxuprXdiaa9+7NmP1RY3O3EUkJzKZ2LNRX0Ps3r27sUPYj5K7iETaeeedx/HHH0/Pnj2ZPj14Ivlf/vIX+vXrR3FxMaeffjoQPEhs/Pjx9O7dmz59+vDkk08CwTdZq82ZM4dx48YBMG7cOCZOnMiAAQO47rrrePHFFxk0aBAlJSWceOKJrFmzBoA9e/Zw7bXX0qtXL/r06cO9997L3//+d84777yaev/617/yla98JaPLrW4ZEYm0GTNm0L59ez799FP69+/PyJEj+drXvsbixYvp1q1bzbNkbr31Vtq2bcvKlSsB2Lp1a8q6KyoqeO6558jLy+Pjjz/mmWeeoVmzZixYsIAbbriBJ598kunTp7NhwwaWL19Os2bN2LJlC+3ateOb3/wmmzZt4rDDDuPBBx/ksssuy+hyK7mLSKRNnTqVp556CoCNGzcyffp0TjnlFLp16wZA+/btAViwYAGPPvpozXzt2rVLWfeoUaPIy8sDggeNXXrppbz++uuYGbt27aqpd+LEiTRr1myf9i6++GIefvhhxo8fz/PPP8+sWbMytMQBJXcRiazy8nIWLFjA888/T6tWrSgrK6Nv376sXr067TrMrOZ1VVXVPtNat25d8/qHP/whp556Kk899RQbNmwg1SPNx48fz7nnnkt+fj6jRo2qSf6Zoj53EYmsbdu20a5dO1q1asXq1atZsmQJVVVVLF68uOYpj9XdMkOHDmXatGk181Z3yxQWFrJq1Sr27t1bcwWQrK3qRwTPnDmzZvzQoUP55S9/WfOha3V7nTp1olOnTtx2222MHz8+cwsdUnIXkZxoXdg6daEM1zds2DB2795Njx49mDx5MgMHDuSwww5j+vTpnH/++RQXFzN69GgAfvCDH7B161Z69epFcXExCxcuBOAnP/kJ55xzDieeeCJHHHFE0rauu+46vv/971NSUrLP3TNXXHEFRx11VM1vtD7yyCM108aOHUvnzp2z8vTMlI/8zRY98lck2vTI39QmTZpESUkJl19+ecLpWX3kr4iIZN7xxx9P69ats/aj20ruIiKNYNmyZVmtX33uIpI1jdXtGwUNXXdK7iKSFfn5+WzevFkJvh7cnc2bN5Ofn1/vOtQtIyJZUVRUREVFBZs2bWrsUA5I+fn5FBUV1Xt+JXcRyYrmzZvXfAtUci9lt4yZzTCzD8zslSTTzcymmtk6M1thZv0yH6aIiNRFOn3uM4FhtUwfDhwT/k0AftHwsEREpCFSJnd3XwxsqaXISGCWB5YAh5pZ8q9xiYhI1mWiz/1IYGPMcEU47t34gmY2geDsnsLCQsrLyzPQfNOz6NRFCcff9NspiWcYm3i0JSm+cMjCOscU70CIUaKrqe9/TT2+dOT0A1V3nw5Mh+DxA6mempbMzXZzwvF1XfFk6RatRSTeMTKlvust1oEQo0RXU9//mnp86chEcn8H6BwzXBSOE8m8Ryzx+P9qIvdSKz5pIjKR3OcCk8zsUWAAsM3d9+uSaYrs5sQ7ut+kHb2xJb86SzKDJd6WyS6LG7qNFZ+OkaYuZXI3s9lAGdDRzCqAm4DmAO5+PzAPOAtYB+wAMv9gYhERqZOUyd3dx6SY7sC3MhaRiIg0mJ4tIyISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRlFZyN7NhZrbGzNaZ2eQE048ys4Vm9i8zW2FmZ2U+VBERSVfK5G5mecA0YDhwHDDGzI6LK/YD4HF3LwEuBO7LdKAiIpK+dM7cTwDWuft6d98JPAqMjCvjwCHh67bAvzMXooiI1FWzNMocCWyMGa4ABsSVmQI8bWZXAq2BMxJVZGYTgAkAhYWFlJeX1zHc3GiqcVVr6vFB049R8TWM4muYXMSXTnJPxxhgprvfbWaDgN+YWS933xtbyN2nA9MBSktLvaysrF6NLWJRA8OtXX3jqtbU44OmH6PiK2vQ/IqvrEHzN/X40pFOt8w7QOeY4aJwXKzLgccB3P15IB/omIkARUSk7tJJ7i8Bx5hZNzNrQfCB6dy4Mm8DpwOYWQ+C5L4pk4GKiEj6UiZ3d98NTALmA6sI7op51cxuMbMRYbHvAl8zs5eB2cA4d/dsBS0iIrVLq8/d3ecB8+LG/Sjm9WvA4MyGJiIi9aVvqIqIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBKWV3M1smJmtMbN1ZjY5SZn/NLPXzOxVM3sks2GKiEhdNEtVwMzygGnAUKACeMnM5rr7azFljgG+Dwx2961m9oVsBSwiIqmlc+Z+ArDO3de7+07gUWBkXJmvAdPcfSuAu3+Q2TBFRKQuUp65A0cCG2OGK4ABcWX+A8DM/gHkAVPc/S/xFZnZBGACQGFhIeXl5fUIOfuaalzVmnp80PRjVHwNo/gaJhfxpZPc063nGKAMKAIWm1lvd/8otpC7TwemA5SWlnpZWVm9GlvEogaEmlp946rW1OODph+j4itr0PyKr6xB8zf1+NKRTrfMO0DnmOGicFysCmCuu+9y9zeBtQTJXkREGkE6yf0l4Bgz62ZmLYALgblxZX5HcNaOmXUk6KZZn7kwRUSkLlImd3ffDUwC5gOrgMfd/VUzu8XMRoTF5gObzew1YCHwPXffnK2gRUSkdmn1ubv7PGBe3Lgfxbx24JrwT0REGpm+oSoiEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEZRWcjezYWa2xszWmdnkWsp91czczEozF6KIiNRVyuRuZnnANGA4cBwwxsyOS1CuAPg28EKmgxQRkbpJ58z9BGCdu693953Ao8DIBOVuBe4AqjIYn4iI1EOzNMocCWyMGa4ABsQWMLN+QGd3/5OZfS9ZRWY2AZgAUFhYSHl5eZ0DzoWmGle1ph4fNP0YFV/DKL6GyUV86ST3WpnZQcBPgXGpyrr7dGA6QGlpqZeVldWrzUUsqtd86apvXNWaenzQ9GNUfGUNml/xlTVo/qYeXzrS6ZZ5B+gcM1wUjqtWAPQCys1sAzAQmKsPVUVEGk86yf0l4Bgz62ZmLYALgbnVE919m7t3dPeu7t4VWAKMcPelWYlYRERSSpnc3X03MAmYD6wCHnf3V83sFjMbke0ARUSk7tLqc3f3ecC8uHE/SlK2rOFhiYhIQ+gbqiIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQWkldzMbZmZrzGydmU1OMP0aM3vNzFaY2d/MrEvmQxURkXSlTO5mlgdMA4YDxwFjzOy4uGL/AkrdvQ8wB7gz04GKiEj60jlzPwFY5+7r3X0n8CgwMraAuy909x3h4BKgKLNhiohIXTRLo8yRwMaY4QpgQC3lLwf+nGiCmU0AJgAUFhZSXl6eXpQ51lTjqtbU44OmH6PiaxjF1zC5iC+d5J42M7sIKAWGJJru7tOB6QClpaVeVlZWr3YWsaieEaanvnFVa+rxQdOPUfGVNWh+xVfWoPmbenzpSCe5vwN0jhkuCsftw8zOAG4Ehrj7Z5kJT0RE6iOdPveXgGPMrJuZtQAuBObGFjCzEuCXwAh3/yDzYYqISF2kTO7uvhuYBMwHVgGPu/urZnaLmY0Ii/0P0AZ4wsyWm9ncJNWJiEgOpNXn7u7zgHlx434U8/qMDMclIiINoG+oiohEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEpZXczWyYma0xs3VmNjnB9JZm9lg4/QUz65rxSEVEJG0pk7uZ5QHTgOHAccAYMzsurtjlwFZ3/xLwM+COTAcqIiLpS+fM/QRgnbuvd/edwKPAyLgyI4GHwtdzgNPNzDIXpoiI1IW5e+0FzC4Ahrn7FeHwxcAAd58UU+aVsExFOPxGWObDuLomABPCwe7AmkwtSAodgQ9Tlmo8TT0+aPoxKr6GUXwNk8v4urj7YakKNctFJNXcfTowPZdtApjZUncvzXW76Wrq8UHTj1HxNYzia5imGF863TLvAJ1jhovCcQnLmFkzoC2wORMBiohI3aWT3F8CjjGzbmbWArgQmBtXZi5wafj6AuDvnqq/R0REsiZlt4y77zazScB8IA+Y4e6vmtktwFJ3nwv8GviNma0DthC8ATQlOe8KqqOmHh80/RgVX8MovoZpcvGl/EBVREQOPPqGqohIBCm5i4hE0AGf3M3MzezhmOFmZrbJzP4YDo8zs/9NMN8GM1tpZivM7GkzOzxHsd4dM3ytmU0JX08xs3fMbLmZrTazX5hZzrePme0JY3jVzF42s++a2UFmdmY4frmZbQ8fR7HczGblIKYbw3hWhG3eZGY/jivT18xWha/bmNkvzewNM1tmZuVmNiBLsW2PeX2Wma01sy7h9txhZl9IUjbpvpBNMdv3FTP7g5kdGo7vamafxmzj5eENFDkXu55ixsUeH6+Z2ZjGiC2M5bxw+x0bDseuu5fN7Dkz695Y8VU74JM78AnQy8wODoeHsv+tmsmc6u59gKXADdkILs5nwPlm1jHJ9J+5e1+Cxzz0BobkIKZ4n7p7X3fvSbAuhwM3ufv8cHxfgvU1Nhy+JJvBmNkg4BygX7itzgAWAqPjil4IzA5fP0Dwwf4x7n48MJ7gSybZjPN0YCow3N3fCkd/CHw3ySyp9oVsqd6+vQjW0bdipr1RvY3Dv505ji2V6uNjJPBLM2veSHGMAZ4N/1erXnfFBN/Wz0U+qVUUkjvAPODs8PUYPj/I07UY+FJGI0psN8Gn6t9JUa4FkA9szXpEtXD3Dwi+UTypER8ncQTwobt/Fsb0obsvBrbGnY3/JzDbzL4IDAB+4O57w3nedPc/ZStAMzsF+BVwjru/ETNpBjDazNonmC3dfSGbngeObMT268XdXwd2AO1y3baZtQFOInieVrK7Ag+hkY9diE5yfxS40MzygT7AC3Wc/xxgZcajSmwaMNbM2iaY9h0zWw68C6x19+U5iikpd19PcAvsF1KVzZKngc5hd8d9ZlZ9NTOb8OAys4HAlvCg7wksd/c9OYqvJfA74Dx3Xx03bTtBgv92knlr2xeyyoIHAp7Ovt9Z+WJMl8y0XMeULjPrB7wennzk2kjgL+6+FthsZseH46vX3RvANcBPGyG2fUQiubv7CqArwVn7vDrMujBMpocAP05RNiPc/WNgFnBVgsnVl51fAFqbWVP7vkDOuft24HiCK4hNwGNmNg54DLgg/Fwitksm13YBzxGcySUyFbjUzAriJ6TYF7Ll4HCffw8oBP4aMy22W+ZbCeduXN8xs1cJTt7+u5FiGENwMkn4v7prpnrdfRG4miZw33skkntoLnAXdTvIT63uN3b3j7ITVkL3ECSD1okmuvsu4C/AKTmMKSEzOxrYAzTGWRIA7r7H3cvd/SZgEvBVd98IvEnwucRXCZI9wKtAcXhmmgt7CbqETjCz/fpZw/3qEfbt2451D7XsC1nwaXgC0QUwksfVFP0s/Czoq8Cvwyv1nAm7104DHjCzDcD3CLZ9fJflXJrAsRul5D4DuNndc9W9Um/uvgV4nCRne2H/9mDgjUTTc8XMDgPuB/63sR4nYWbdzeyYmFF9geoPLGcT/H7A+uonkoZ93kuBm6s/JwjvZjibLHH3HQSf+Yw1s0Tb9KfA10nwjfBU+0K2hDFfBXzXgudBHTDCb8Uv5fNHnuTKBcBv3L2Lu3d1984EJxid48qdRCMfuxCh5O7uFe4+NcnkcWZWEfNXlNPgErub/e/gqO5zf4Wgn/u+XAdFeNkeXv4uIOjzvrkR4qjWBngovP1tBcGdRFPCaU8Q9LHHX61dQdDlsM6Cx1HPJMtXHmGSHgb8wMxGxE37EHiKoH8+kUT7Qta5+7+AFex710dT0CrueL0mQZlbgGsst7cLjyHYjrGeBL7P533uLwO3E+yDjUqPHxARiaDInLmLiMjnlNxFRCJIyV1EJIKU3EVEIkjJXUQkgpTcRUQiSMldRCSC/h/b8VX3I+NT2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "bar_width=0.15\n",
    "plt.bar(x,accuracy,width=bar_width,color='purple',zorder=2)\n",
    "plt.bar(x+bar_width,precision,width=bar_width,color='orange',zorder=2)\n",
    "plt.bar(x+bar_width*2,recall,width=bar_width,color='red',zorder=2)\n",
    "plt.bar(x+bar_width*3,fscore,width=bar_width,color='green',zorder=2)\n",
    "\n",
    "\n",
    "#for labeling part\n",
    "plt.xticks(x+bar_width*1.5,['MLP','NB',\"DT\",\"SVC\",\"KNN\",\"RF\",\"LR\",\"AB\"])\n",
    "plt.title('Results on kc2 dataset without feature selection method')\n",
    "\n",
    "#for making patches\n",
    "green=mpatches.Patch(color='purple',label='accuracy')\n",
    "orange=mpatches.Patch(color='orange',label='precision')\n",
    "red=mpatches.Patch(color='red',label='recall')\n",
    "purple=mpatches.Patch(color='green',label='fscore')\n",
    "plt.legend(handles=[purple,orange,red,green])\n",
    "plt.ylim(0,1.5)\n",
    "\n",
    "#grid\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
