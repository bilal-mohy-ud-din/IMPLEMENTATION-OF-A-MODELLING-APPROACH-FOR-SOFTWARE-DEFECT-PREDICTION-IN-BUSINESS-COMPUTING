{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04f4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#importing dataset\n",
    "data = pd.read_csv('kc1_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233e3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2109 entries, 0 to 2108\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc                2109 non-null   float64\n",
      " 1   v(g)               2109 non-null   float64\n",
      " 2   ev(g)              2109 non-null   float64\n",
      " 3   iv(g)              2109 non-null   float64\n",
      " 4   n                  2109 non-null   float64\n",
      " 5   v                  2109 non-null   float64\n",
      " 6   l                  2109 non-null   float64\n",
      " 7   d                  2109 non-null   float64\n",
      " 8   i                  2109 non-null   float64\n",
      " 9   e                  2109 non-null   float64\n",
      " 10  b                  2109 non-null   float64\n",
      " 11  t                  2109 non-null   float64\n",
      " 12  lOCode             2109 non-null   int64  \n",
      " 13  lOComment          2109 non-null   int64  \n",
      " 14  lOBlank            2109 non-null   int64  \n",
      " 15  locCodeAndComment  2109 non-null   int64  \n",
      " 16  uniq_Op            2109 non-null   float64\n",
      " 17  uniq_Opnd          2109 non-null   float64\n",
      " 18  total_Op           2109 non-null   float64\n",
      " 19  total_Opnd         2109 non-null   float64\n",
      " 20  branchCount        2109 non-null   float64\n",
      " 21  defects            2109 non-null   bool   \n",
      "dtypes: bool(1), float64(17), int64(4)\n",
      "memory usage: 348.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() #informs about the data (memory usage, data types etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9c980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>927.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>23.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>21378.61</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>769.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>11436.73</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>254.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.35</td>\n",
       "      <td>27.25</td>\n",
       "      <td>2381.95</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>569.73</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.27</td>\n",
       "      <td>50.53</td>\n",
       "      <td>6423.73</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>751.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.43</td>\n",
       "      <td>48.72</td>\n",
       "      <td>11596.34</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1212.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>27.27</td>\n",
       "      <td>44.45</td>\n",
       "      <td>33061.94</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>745.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.20</td>\n",
       "      <td>45.99</td>\n",
       "      <td>12069.00</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>801.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.82</td>\n",
       "      <td>44.97</td>\n",
       "      <td>14278.39</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc  v(g)  ev(g)  iv(g)      n        v     l      d      i         e  \\\n",
       "0   1.1   1.4    1.4    1.4    1.3     1.30  1.30   1.30   1.30      1.30   \n",
       "1   1.0   1.0    1.0    1.0    1.0     1.00  1.00   1.00   1.00      1.00   \n",
       "2  83.0  11.0    1.0   11.0  171.0   927.89  0.04  23.04  40.27  21378.61   \n",
       "3  46.0   8.0    6.0    8.0  141.0   769.78  0.07  14.86  51.81  11436.73   \n",
       "4  25.0   3.0    1.0    3.0   58.0   254.75  0.11   9.35  27.25   2381.95   \n",
       "5  43.0   3.0    1.0    3.0  115.0   569.73  0.09  11.27  50.53   6423.73   \n",
       "6  48.0   6.0    1.0    6.0  149.0   751.61  0.06  15.43  48.72  11596.34   \n",
       "7  69.0  12.0    1.0   12.0  231.0  1212.27  0.04  27.27  44.45  33061.94   \n",
       "8  47.0   6.0    1.0    6.0  149.0   745.00  0.06  16.20  45.99  12069.00   \n",
       "9  48.0   7.0    1.0    7.0  155.0   801.34  0.06  17.82  44.97  14278.39   \n",
       "\n",
       "   ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0  ...       2          2        2                  2      1.2        1.2   \n",
       "1  ...       1          1        1                  1      1.0        1.0   \n",
       "2  ...      65         10        6                  0     18.0       25.0   \n",
       "3  ...      37          2        5                  0     16.0       28.0   \n",
       "4  ...      21          0        2                  0     11.0       10.0   \n",
       "5  ...      35          2        4                  0     11.0       20.0   \n",
       "6  ...      41          2        2                  0     12.0       21.0   \n",
       "7  ...      62          3        2                  0     16.0       22.0   \n",
       "8  ...      41          2        1                  0     12.0       20.0   \n",
       "9  ...      42          2        1                  0     14.0       22.0   \n",
       "\n",
       "   total_Op  total_Opnd  branchCount  defects  \n",
       "0       1.2         1.2          1.4    False  \n",
       "1       1.0         1.0          1.0     True  \n",
       "2     107.0        64.0         21.0     True  \n",
       "3      89.0        52.0         15.0     True  \n",
       "4      41.0        17.0          5.0     True  \n",
       "5      74.0        41.0          5.0     True  \n",
       "6      95.0        54.0         11.0     True  \n",
       "7     156.0        75.0         23.0     True  \n",
       "8      95.0        54.0         11.0     True  \n",
       "9      99.0        56.0         13.0     True  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf01770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:28]\n",
    "y=data.iloc[:,-1]\n",
    "#preprocessing \n",
    "#changing categorical into numerical values\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_y=preprocessing.LabelEncoder()\n",
    "y=encoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf655522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a0548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 221\n",
      "Before OverSampling, counts of label '0': 1255 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of Labels in the Training Set\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9e02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Over Sampling, counts of label '1': 1255\n",
      "After Over Sampling, counts of label '0': 1255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over = SMOTE(random_state = 1)\n",
    "X_train2, y_train2 = over.fit_resample(X_train, y_train.ravel())\n",
    "print(\"After Over Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Over Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31985bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Under Sampling, counts of label '1': 221\n",
      "After Under Sampling, counts of label '0': 221\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(random_state = 1)\n",
    "X_train2, y_train2 = under.fit_resample(X_train, y_train.ravel())\n",
    "  \n",
    "print(\"After Under Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Under Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f5c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce56a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "accuracy_score 0.9968\n",
      "precision_score=0.9969\n",
      "recall_score=0.9968\n",
      "f-score_score=0.9969\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with MLP\n",
    "classifier1=MLPClassifier(activation = 'tanh',max_iter=1000,alpha= 0.0001)\n",
    "classifier1.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_mlp=classifier1.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_mlp)\n",
    "accuracy_score_mlp=metrics.accuracy_score(y_test,y_pred_mlp)\n",
    "print('MLPClassifier')\n",
    "print(\"accuracy_score {:.4f}\".format(accuracy_score_mlp))\n",
    "\n",
    "#for precision\n",
    "precision_mlp=metrics.precision_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_mlp))\n",
    "\n",
    "#for recall\n",
    "recall_mlp=metrics.recall_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_mlp))\n",
    "\n",
    "#for f-score\n",
    "fscore_mlp=metrics.f1_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"f-score_score={:.4f}\".format(fscore_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f319d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with naive bayes\n",
    "classifier2=GaussianNB()\n",
    "classifier2.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_nb=classifier2.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_nb)\n",
    "accuracy_score_nb=metrics.accuracy_score(y_test,y_pred_nb)\n",
    "print('Naive Bayes Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_nb))\n",
    "\n",
    "#for precision\n",
    "precision_nb=metrics.precision_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_nb))\n",
    "\n",
    "#for  recall\n",
    "recall_nb=metrics.recall_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_nb))\n",
    "\n",
    "#for  f-score\n",
    "fscore_nb=metrics.f1_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac29eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with Deecision Tree\n",
    "classifier3=DecisionTreeClassifier()\n",
    "classifier3.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_DT=classifier3.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_DT)\n",
    "accuracy_score_DT=metrics.accuracy_score(y_test,y_pred_DT)\n",
    "print('Decision Tree Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_DT))\n",
    "\n",
    "#for precision\n",
    "precision_DT=metrics.precision_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_DT))\n",
    "\n",
    "#for  recall\n",
    "recall_DT=metrics.recall_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_DT))\n",
    "\n",
    "#for f-score\n",
    "fscore_DT=metrics.f1_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26178ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector Classifier\n",
      "accuracy_score0.9731\n",
      "precision_score=0.9769\n",
      "recall_score=0.9731\n",
      "f-score=0.9739\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with svm\n",
    "from sklearn.svm import SVC\n",
    "classifier4=SVC(probability=True,C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "classifier4.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_svm=classifier4.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_svm)\n",
    "accuracy_score_svm=metrics.accuracy_score(y_test,y_pred_svm)\n",
    "print('Support vector Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_svm))\n",
    "\n",
    "#for precision\n",
    "precision_svm=metrics.precision_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_svm))\n",
    "\n",
    "#for recall\n",
    "recall_svm=metrics.recall_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_svm))\n",
    "\n",
    "#for f-score\n",
    "fscore_svm=metrics.f1_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3c238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "accuracy_score0.9716\n",
      "precision_score=0.9757\n",
      "recall_score=0.9716\n",
      "f-score=0.9724\n"
     ]
    }
   ],
   "source": [
    "#fitting model with KNeighborsClassifier\n",
    "classifier5=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier5.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_knn=classifier5.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_knn)\n",
    "accuracy_score_knn=metrics.accuracy_score(y_test,y_pred_knn)\n",
    "print('KNeighborsClassifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_knn))\n",
    "\n",
    "#for precision\n",
    "precision_knn=metrics.precision_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_knn))\n",
    "\n",
    "#for recall\n",
    "recall_knn=metrics.recall_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_knn))\n",
    "\n",
    "#for f-score\n",
    "fscore_knn=metrics.f1_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ae7407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with RandomForest\n",
    "classifier6=RandomForestClassifier()\n",
    "classifier6.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_rf=classifier6.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_rf)\n",
    "accuracy_score_rf=metrics.accuracy_score(y_test,y_pred_rf)\n",
    "print('RandomForest')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_rf))\n",
    "\n",
    "#for precision\n",
    "precision_rf=metrics.precision_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_rf))\n",
    "\n",
    "#for recall\n",
    "recall_rf=metrics.recall_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_rf))\n",
    "\n",
    "#for f-score\n",
    "fscore_rf=metrics.f1_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11bac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with LogisticRegression\n",
    "classifier7=LogisticRegression()\n",
    "classifier7.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_lr=classifier7.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_lr)\n",
    "accuracy_score_lr=metrics.accuracy_score(y_test,y_pred_lr)\n",
    "print('LogisticRegression')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_lr))\n",
    "\n",
    "#for precision\n",
    "precision_lr=metrics.precision_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_lr))\n",
    "\n",
    "#for recall\n",
    "recall_lr=metrics.recall_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_lr))\n",
    "\n",
    "#for f-score\n",
    "fscore_lr=metrics.f1_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "accuracy_score=1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with AdaBoostClassifier\n",
    "classifier8=AdaBoostClassifier()\n",
    "classifier8.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_AB=classifier8.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_AB)\n",
    "accuracy_score_AB=metrics.accuracy_score(y_test,y_pred_AB)\n",
    "print('GradientBoosting')\n",
    "print(\"accuracy_score={:.4f}\".format(accuracy_score_AB))\n",
    "\n",
    "#for precision\n",
    "precision_AB=metrics.precision_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_AB))\n",
    "\n",
    "#for recall\n",
    "recall_AB=metrics.recall_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_AB))\n",
    "\n",
    "#for f-score\n",
    "fscore_AB=metrics.f1_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0ab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising plots\n",
    "accuracy=np.array([accuracy_score_mlp,accuracy_score_nb,accuracy_score_DT,accuracy_score_svm,accuracy_score_knn,accuracy_score_rf,accuracy_score_lr,accuracy_score_AB])\n",
    "precision=np.array([precision_mlp,precision_nb,precision_DT,precision_svm,precision_knn,precision_rf,precision_lr,precision_AB])\n",
    "recall=np.array([recall_mlp,recall_nb,recall_DT,recall_svm,recall_knn,recall_rf,recall_lr,recall_AB])\n",
    "fscore=np.array([fscore_knn,fscore_nb,fscore_DT,fscore_svm,fscore_knn,fscore_rf,fscore_lr,fscore_AB])\n",
    "x=np.arange(len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfe5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "bar_width=0.15\n",
    "plt.bar(x,accuracy,width=bar_width,color='purple',zorder=2)\n",
    "plt.bar(x+bar_width,precision,width=bar_width,color='orange',zorder=2)\n",
    "plt.bar(x+bar_width*2,recall,width=bar_width,color='red',zorder=2)\n",
    "plt.bar(x+bar_width*3,fscore,width=bar_width,color='green',zorder=2)\n",
    "\n",
    "\n",
    "#for labeling part\n",
    "plt.xticks(x+bar_width*1.5,['MLP','NB',\"DT\",\"SVC\",\"KNN\",\"RF\",\"LR\",\"AB\"])\n",
    "plt.title('Results on kc1 dataset without feaure selection method')\n",
    "\n",
    "#for making patches\n",
    "green=mpatches.Patch(color='purple',label='accuracy')\n",
    "orange=mpatches.Patch(color='orange',label='precision')\n",
    "red=mpatches.Patch(color='red',label='recall')\n",
    "purple=mpatches.Patch(color='green',label='fscore')\n",
    "plt.legend(handles=[purple,orange,red,green])\n",
    "plt.ylim(0,1.5)\n",
    "\n",
    "#grid\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
