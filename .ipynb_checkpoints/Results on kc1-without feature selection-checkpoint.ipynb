{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04f4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#importing dataset\n",
    "data = pd.read_csv('jm1_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233e3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10885 entries, 0 to 10884\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc                10885 non-null  float64\n",
      " 1   v(g)               10885 non-null  float64\n",
      " 2   ev(g)              10885 non-null  float64\n",
      " 3   iv(g)              10885 non-null  float64\n",
      " 4   n                  10885 non-null  float64\n",
      " 5   v                  10885 non-null  float64\n",
      " 6   l                  10885 non-null  float64\n",
      " 7   d                  10885 non-null  float64\n",
      " 8   i                  10885 non-null  float64\n",
      " 9   e                  10885 non-null  float64\n",
      " 10  b                  10885 non-null  float64\n",
      " 11  t                  10885 non-null  float64\n",
      " 12  lOCode             10885 non-null  int64  \n",
      " 13  lOComment          10885 non-null  int64  \n",
      " 14  lOBlank            10885 non-null  int64  \n",
      " 15  locCodeAndComment  10885 non-null  int64  \n",
      " 16  uniq_Op            10885 non-null  float64\n",
      " 17  uniq_Opnd          10885 non-null  float64\n",
      " 18  total_Op           10885 non-null  float64\n",
      " 19  total_Opnd         10885 non-null  float64\n",
      " 20  branchCount        10885 non-null  float64\n",
      " 21  defects            10885 non-null  bool   \n",
      "dtypes: bool(1), float64(17), int64(4)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #informs about the data (memory usage, data types etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9c980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>17.43</td>\n",
       "      <td>69.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>6.43</td>\n",
       "      <td>14.62</td>\n",
       "      <td>604.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>548.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.25</td>\n",
       "      <td>38.51</td>\n",
       "      <td>7820.87</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1362.41</td>\n",
       "      <td>0.04</td>\n",
       "      <td>22.30</td>\n",
       "      <td>61.10</td>\n",
       "      <td>30377.95</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc  v(g)  ev(g)  iv(g)      n        v     l      d      i         e  \\\n",
       "0   1.1   1.4    1.4    1.4    1.3     1.30  1.30   1.30   1.30      1.30   \n",
       "1   1.0   1.0    1.0    1.0    1.0     1.00  1.00   1.00   1.00      1.00   \n",
       "2  24.0   5.0    1.0    3.0   63.0   309.13  0.11   9.50  32.54   2936.77   \n",
       "3  20.0   4.0    4.0    2.0   47.0   215.49  0.06  16.00  13.47   3447.89   \n",
       "4  24.0   6.0    6.0    2.0   72.0   346.13  0.06  17.33  19.97   5999.58   \n",
       "5  24.0   6.0    6.0    2.0   72.0   346.13  0.06  17.33  19.97   5999.58   \n",
       "6   7.0   1.0    1.0    1.0   11.0    34.87  0.50   2.00  17.43     69.74   \n",
       "7  12.0   2.0    1.0    2.0   23.0    94.01  0.16   6.43  14.62    604.36   \n",
       "8  25.0   5.0    5.0    5.0  107.0   548.83  0.07  14.25  38.51   7820.87   \n",
       "9  46.0  15.0    3.0    1.0  239.0  1362.41  0.04  22.30  61.10  30377.95   \n",
       "\n",
       "   ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0  ...       2          2        2                  2      1.2        1.2   \n",
       "1  ...       1          1        1                  1      1.0        1.0   \n",
       "2  ...       1          0        6                  0     15.0       15.0   \n",
       "3  ...       0          0        3                  0     16.0        8.0   \n",
       "4  ...       0          0        3                  0     16.0       12.0   \n",
       "5  ...       0          0        3                  0     16.0       12.0   \n",
       "6  ...       0          0        1                  0      4.0        5.0   \n",
       "7  ...       0          0        7                  0     10.0        7.0   \n",
       "8  ...      12         16       13                  0     15.0       20.0   \n",
       "9  ...       8         35       22                  0     15.0       37.0   \n",
       "\n",
       "   total_Op  total_Opnd  branchCount  defects  \n",
       "0       1.2         1.2          1.4    False  \n",
       "1       1.0         1.0          1.0     True  \n",
       "2      44.0        19.0          9.0    False  \n",
       "3      31.0        16.0          7.0    False  \n",
       "4      46.0        26.0         11.0    False  \n",
       "5      46.0        26.0         11.0    False  \n",
       "6       6.0         5.0          1.0    False  \n",
       "7      14.0         9.0          3.0    False  \n",
       "8      69.0        38.0          9.0    False  \n",
       "9     129.0       110.0         29.0    False  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf01770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:28]\n",
    "y=data.iloc[:,-1]\n",
    "#preprocessing \n",
    "#changing categorical into numerical values\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_y=preprocessing.LabelEncoder()\n",
    "y=encoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf655522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a0548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 893\n",
      "Before OverSampling, counts of label '0': 6726 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of Labels in the Training Set\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9e02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Over Sampling, counts of label '1': 6726\n",
      "After Over Sampling, counts of label '0': 6726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over = SMOTE(random_state = 1)\n",
    "X_train2, y_train2 = over.fit_resample(X_train, y_train.ravel())\n",
    "print(\"After Over Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Over Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31985bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Under Sampling, counts of label '1': 893\n",
      "After Under Sampling, counts of label '0': 893\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(random_state = 1)\n",
    "X_train2, y_train2 = under.fit_resample(X_train, y_train.ravel())\n",
    "  \n",
    "print(\"After Under Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Under Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f5c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce56a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "accuracy_score 1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score_score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with MLP\n",
    "classifier1=MLPClassifier(activation = 'tanh',max_iter=1000,alpha= 0.0001)\n",
    "classifier1.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_mlp=classifier1.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_mlp)\n",
    "accuracy_score_mlp=metrics.accuracy_score(y_test,y_pred_mlp)\n",
    "print('MLPClassifier')\n",
    "print(\"accuracy_score {:.4f}\".format(accuracy_score_mlp))\n",
    "\n",
    "#for precision\n",
    "precision_mlp=metrics.precision_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_mlp))\n",
    "\n",
    "#for recall\n",
    "recall_mlp=metrics.recall_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_mlp))\n",
    "\n",
    "#for f-score\n",
    "fscore_mlp=metrics.f1_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"f-score_score={:.4f}\".format(fscore_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f319d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with naive bayes\n",
    "classifier2=GaussianNB()\n",
    "classifier2.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_nb=classifier2.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_nb)\n",
    "accuracy_score_nb=metrics.accuracy_score(y_test,y_pred_nb)\n",
    "print('Naive Bayes Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_nb))\n",
    "\n",
    "#for precision\n",
    "precision_nb=metrics.precision_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_nb))\n",
    "\n",
    "#for  recall\n",
    "recall_nb=metrics.recall_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_nb))\n",
    "\n",
    "#for  f-score\n",
    "fscore_nb=metrics.f1_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac29eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with Deecision Tree\n",
    "classifier3=DecisionTreeClassifier()\n",
    "classifier3.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_DT=classifier3.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_DT)\n",
    "accuracy_score_DT=metrics.accuracy_score(y_test,y_pred_DT)\n",
    "print('Decision Tree Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_DT))\n",
    "\n",
    "#for precision\n",
    "precision_DT=metrics.precision_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_DT))\n",
    "\n",
    "#for  recall\n",
    "recall_DT=metrics.recall_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_DT))\n",
    "\n",
    "#for f-score\n",
    "fscore_DT=metrics.f1_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26178ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector Classifier\n",
      "accuracy_score0.9997\n",
      "precision_score=0.9997\n",
      "recall_score=0.9997\n",
      "f-score=0.9997\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with svm\n",
    "from sklearn.svm import SVC\n",
    "classifier4=SVC(probability=True,C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "classifier4.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_svm=classifier4.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_svm)\n",
    "accuracy_score_svm=metrics.accuracy_score(y_test,y_pred_svm)\n",
    "print('Support vector Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_svm))\n",
    "\n",
    "#for precision\n",
    "precision_svm=metrics.precision_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_svm))\n",
    "\n",
    "#for recall\n",
    "recall_svm=metrics.recall_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_svm))\n",
    "\n",
    "#for f-score\n",
    "fscore_svm=metrics.f1_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3c238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "accuracy_score0.9917\n",
      "precision_score=0.9923\n",
      "recall_score=0.9917\n",
      "f-score=0.9919\n"
     ]
    }
   ],
   "source": [
    "#fitting model with KNeighborsClassifier\n",
    "classifier5=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier5.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_knn=classifier5.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_knn)\n",
    "accuracy_score_knn=metrics.accuracy_score(y_test,y_pred_knn)\n",
    "print('KNeighborsClassifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_knn))\n",
    "\n",
    "#for precision\n",
    "precision_knn=metrics.precision_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_knn))\n",
    "\n",
    "#for recall\n",
    "recall_knn=metrics.recall_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_knn))\n",
    "\n",
    "#for f-score\n",
    "fscore_knn=metrics.f1_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ae7407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with RandomForest\n",
    "classifier6=RandomForestClassifier()\n",
    "classifier6.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_rf=classifier6.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_rf)\n",
    "accuracy_score_rf=metrics.accuracy_score(y_test,y_pred_rf)\n",
    "print('RandomForest')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_rf))\n",
    "\n",
    "#for precision\n",
    "precision_rf=metrics.precision_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_rf))\n",
    "\n",
    "#for recall\n",
    "recall_rf=metrics.recall_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_rf))\n",
    "\n",
    "#for f-score\n",
    "fscore_rf=metrics.f1_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11bac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with LogisticRegression\n",
    "classifier7=LogisticRegression()\n",
    "classifier7.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_lr=classifier7.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_lr)\n",
    "accuracy_score_lr=metrics.accuracy_score(y_test,y_pred_lr)\n",
    "print('LogisticRegression')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_lr))\n",
    "\n",
    "#for precision\n",
    "precision_lr=metrics.precision_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_lr))\n",
    "\n",
    "#for recall\n",
    "recall_lr=metrics.recall_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_lr))\n",
    "\n",
    "#for f-score\n",
    "fscore_lr=metrics.f1_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "accuracy_score=1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with AdaBoostClassifier\n",
    "classifier8=AdaBoostClassifier()\n",
    "classifier8.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_AB=classifier8.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_AB)\n",
    "accuracy_score_AB=metrics.accuracy_score(y_test,y_pred_AB)\n",
    "print('GradientBoosting')\n",
    "print(\"accuracy_score={:.4f}\".format(accuracy_score_AB))\n",
    "\n",
    "#for precision\n",
    "precision_AB=metrics.precision_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_AB))\n",
    "\n",
    "#for recall\n",
    "recall_AB=metrics.recall_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_AB))\n",
    "\n",
    "#for f-score\n",
    "fscore_AB=metrics.f1_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0ab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising plots\n",
    "accuracy=np.array([accuracy_score_mlp,accuracy_score_nb,accuracy_score_DT,accuracy_score_svm,accuracy_score_knn,accuracy_score_rf,accuracy_score_lr,accuracy_score_AB])\n",
    "precision=np.array([precision_mlp,precision_nb,precision_DT,precision_svm,precision_knn,precision_rf,precision_lr,precision_AB])\n",
    "recall=np.array([recall_mlp,recall_nb,recall_DT,recall_svm,recall_knn,recall_rf,recall_lr,recall_AB])\n",
    "fscore=np.array([fscore_knn,fscore_nb,fscore_DT,fscore_svm,fscore_knn,fscore_rf,fscore_lr,fscore_AB])\n",
    "x=np.arange(len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfe5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "bar_width=0.15\n",
    "plt.bar(x,accuracy,width=bar_width,color='purple',zorder=2)\n",
    "plt.bar(x+bar_width,precision,width=bar_width,color='orange',zorder=2)\n",
    "plt.bar(x+bar_width*2,recall,width=bar_width,color='red',zorder=2)\n",
    "plt.bar(x+bar_width*3,fscore,width=bar_width,color='green',zorder=2)\n",
    "\n",
    "\n",
    "#for labeling part\n",
    "plt.xticks(x+bar_width*1.5,['MLP','NB',\"DT\",\"SVC\",\"KNN\",\"RF\",\"LR\",\"AB\"])\n",
    "plt.title('Results on Jm1 dataset without feaure selection method')\n",
    "\n",
    "#for making patches\n",
    "green=mpatches.Patch(color='purple',label='accuracy')\n",
    "orange=mpatches.Patch(color='orange',label='precision')\n",
    "red=mpatches.Patch(color='red',label='recall')\n",
    "purple=mpatches.Patch(color='green',label='fscore')\n",
    "plt.legend(handles=[purple,orange,red,green])\n",
    "plt.ylim(0,1.5)\n",
    "\n",
    "#grid\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
