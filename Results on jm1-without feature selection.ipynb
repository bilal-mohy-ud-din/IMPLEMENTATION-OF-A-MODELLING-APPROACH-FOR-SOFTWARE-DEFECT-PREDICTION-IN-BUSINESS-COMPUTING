{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04f4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#importing dataset\n",
    "data = pd.read_csv('jm1_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233e3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10885 entries, 0 to 10884\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc                10885 non-null  float64\n",
      " 1   v(g)               10885 non-null  float64\n",
      " 2   ev(g)              10885 non-null  float64\n",
      " 3   iv(g)              10885 non-null  float64\n",
      " 4   n                  10885 non-null  float64\n",
      " 5   v                  10885 non-null  float64\n",
      " 6   l                  10885 non-null  float64\n",
      " 7   d                  10885 non-null  float64\n",
      " 8   i                  10885 non-null  float64\n",
      " 9   e                  10885 non-null  float64\n",
      " 10  b                  10885 non-null  float64\n",
      " 11  t                  10885 non-null  float64\n",
      " 12  lOCode             10885 non-null  int64  \n",
      " 13  lOComment          10885 non-null  int64  \n",
      " 14  lOBlank            10885 non-null  int64  \n",
      " 15  locCodeAndComment  10885 non-null  int64  \n",
      " 16  uniq_Op            10885 non-null  float64\n",
      " 17  uniq_Opnd          10885 non-null  float64\n",
      " 18  total_Op           10885 non-null  float64\n",
      " 19  total_Opnd         10885 non-null  float64\n",
      " 20  branchCount        10885 non-null  float64\n",
      " 21  defects            10885 non-null  bool   \n",
      "dtypes: bool(1), float64(17), int64(4)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #informs about the data (memory usage, data types etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9c980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>17.43</td>\n",
       "      <td>69.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>6.43</td>\n",
       "      <td>14.62</td>\n",
       "      <td>604.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>548.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.25</td>\n",
       "      <td>38.51</td>\n",
       "      <td>7820.87</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1362.41</td>\n",
       "      <td>0.04</td>\n",
       "      <td>22.30</td>\n",
       "      <td>61.10</td>\n",
       "      <td>30377.95</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc  v(g)  ev(g)  iv(g)      n        v     l      d      i         e  \\\n",
       "0   1.1   1.4    1.4    1.4    1.3     1.30  1.30   1.30   1.30      1.30   \n",
       "1   1.0   1.0    1.0    1.0    1.0     1.00  1.00   1.00   1.00      1.00   \n",
       "2  24.0   5.0    1.0    3.0   63.0   309.13  0.11   9.50  32.54   2936.77   \n",
       "3  20.0   4.0    4.0    2.0   47.0   215.49  0.06  16.00  13.47   3447.89   \n",
       "4  24.0   6.0    6.0    2.0   72.0   346.13  0.06  17.33  19.97   5999.58   \n",
       "5  24.0   6.0    6.0    2.0   72.0   346.13  0.06  17.33  19.97   5999.58   \n",
       "6   7.0   1.0    1.0    1.0   11.0    34.87  0.50   2.00  17.43     69.74   \n",
       "7  12.0   2.0    1.0    2.0   23.0    94.01  0.16   6.43  14.62    604.36   \n",
       "8  25.0   5.0    5.0    5.0  107.0   548.83  0.07  14.25  38.51   7820.87   \n",
       "9  46.0  15.0    3.0    1.0  239.0  1362.41  0.04  22.30  61.10  30377.95   \n",
       "\n",
       "   ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0  ...       2          2        2                  2      1.2        1.2   \n",
       "1  ...       1          1        1                  1      1.0        1.0   \n",
       "2  ...       1          0        6                  0     15.0       15.0   \n",
       "3  ...       0          0        3                  0     16.0        8.0   \n",
       "4  ...       0          0        3                  0     16.0       12.0   \n",
       "5  ...       0          0        3                  0     16.0       12.0   \n",
       "6  ...       0          0        1                  0      4.0        5.0   \n",
       "7  ...       0          0        7                  0     10.0        7.0   \n",
       "8  ...      12         16       13                  0     15.0       20.0   \n",
       "9  ...       8         35       22                  0     15.0       37.0   \n",
       "\n",
       "   total_Op  total_Opnd  branchCount  defects  \n",
       "0       1.2         1.2          1.4    False  \n",
       "1       1.0         1.0          1.0     True  \n",
       "2      44.0        19.0          9.0    False  \n",
       "3      31.0        16.0          7.0    False  \n",
       "4      46.0        26.0         11.0    False  \n",
       "5      46.0        26.0         11.0    False  \n",
       "6       6.0         5.0          1.0    False  \n",
       "7      14.0         9.0          3.0    False  \n",
       "8      69.0        38.0          9.0    False  \n",
       "9     129.0       110.0         29.0    False  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf01770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:28]\n",
    "y=data.iloc[:,-1]\n",
    "#preprocessing \n",
    "#changing categorical into numerical values\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_y=preprocessing.LabelEncoder()\n",
    "y=encoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf655522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a0548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 909\n",
      "Before OverSampling, counts of label '0': 6710 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of Labels in the Training Set\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9e02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Over Sampling, counts of label '1': 6710\n",
      "After Over Sampling, counts of label '0': 6710\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over = SMOTE(random_state = 1)\n",
    "X_train2, y_train2 = over.fit_resample(X_train, y_train.ravel())\n",
    "print(\"After Over Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Over Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31985bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Under Sampling, counts of label '1': 909\n",
      "After Under Sampling, counts of label '0': 909\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(random_state = 1)\n",
    "X_train2, y_train2 = under.fit_resample(X_train, y_train.ravel())\n",
    "  \n",
    "print(\"After Under Sampling, counts of label '1': {}\".format(sum(y_train2 == 1)))\n",
    "print(\"After Under Sampling, counts of label '0': {}\".format(sum(y_train2 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f5c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce56a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "accuracy_score 0.9994\n",
      "precision_score=0.9994\n",
      "recall_score=0.9994\n",
      "f-score_score=0.9994\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with MLP\n",
    "classifier1=MLPClassifier(activation = 'tanh',max_iter=1000,alpha= 0.0001)\n",
    "classifier1.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_mlp=classifier1.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_mlp)\n",
    "accuracy_score_mlp=metrics.accuracy_score(y_test,y_pred_mlp)\n",
    "print('MLPClassifier')\n",
    "print(\"accuracy_score {:.4f}\".format(accuracy_score_mlp))\n",
    "\n",
    "#for precision\n",
    "precision_mlp=metrics.precision_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_mlp))\n",
    "\n",
    "#for recall\n",
    "recall_mlp=metrics.recall_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_mlp))\n",
    "\n",
    "#for f-score\n",
    "fscore_mlp=metrics.f1_score(y_test,y_pred_mlp,average='weighted')\n",
    "print(\"f-score_score={:.4f}\".format(fscore_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f319d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with naive bayes\n",
    "classifier2=GaussianNB()\n",
    "classifier2.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_nb=classifier2.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_nb)\n",
    "accuracy_score_nb=metrics.accuracy_score(y_test,y_pred_nb)\n",
    "print('Naive Bayes Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_nb))\n",
    "\n",
    "#for precision\n",
    "precision_nb=metrics.precision_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_nb))\n",
    "\n",
    "#for  recall\n",
    "recall_nb=metrics.recall_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_nb))\n",
    "\n",
    "#for  f-score\n",
    "fscore_nb=metrics.f1_score(y_test,y_pred_nb,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac29eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with Deecision Tree\n",
    "classifier3=DecisionTreeClassifier()\n",
    "classifier3.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_DT=classifier3.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_DT)\n",
    "accuracy_score_DT=metrics.accuracy_score(y_test,y_pred_DT)\n",
    "print('Decision Tree Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_DT))\n",
    "\n",
    "#for precision\n",
    "precision_DT=metrics.precision_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_DT))\n",
    "\n",
    "#for  recall\n",
    "recall_DT=metrics.recall_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_DT))\n",
    "\n",
    "#for f-score\n",
    "fscore_DT=metrics.f1_score(y_test,y_pred_DT,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26178ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector Classifier\n",
      "accuracy_score0.9991\n",
      "precision_score=0.9991\n",
      "recall_score=0.9991\n",
      "f-score=0.9991\n"
     ]
    }
   ],
   "source": [
    "#fitting our model with svm\n",
    "from sklearn.svm import SVC\n",
    "classifier4=SVC(probability=True,C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "classifier4.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_svm=classifier4.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_svm)\n",
    "accuracy_score_svm=metrics.accuracy_score(y_test,y_pred_svm)\n",
    "print('Support vector Classifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_svm))\n",
    "\n",
    "#for precision\n",
    "precision_svm=metrics.precision_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_svm))\n",
    "\n",
    "#for recall\n",
    "recall_svm=metrics.recall_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_svm))\n",
    "\n",
    "#for f-score\n",
    "fscore_svm=metrics.f1_score(y_test,y_pred_svm,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3c238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "accuracy_score0.9933\n",
      "precision_score=0.9936\n",
      "recall_score=0.9933\n",
      "f-score=0.9933\n"
     ]
    }
   ],
   "source": [
    "#fitting model with KNeighborsClassifier\n",
    "classifier5=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier5.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_knn=classifier5.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_knn)\n",
    "accuracy_score_knn=metrics.accuracy_score(y_test,y_pred_knn)\n",
    "print('KNeighborsClassifier')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_knn))\n",
    "\n",
    "#for precision\n",
    "precision_knn=metrics.precision_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_knn))\n",
    "\n",
    "#for recall\n",
    "recall_knn=metrics.recall_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_knn))\n",
    "\n",
    "#for f-score\n",
    "fscore_knn=metrics.f1_score(y_test,y_pred_knn,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ae7407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with RandomForest\n",
    "classifier6=RandomForestClassifier()\n",
    "classifier6.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_rf=classifier6.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_rf)\n",
    "accuracy_score_rf=metrics.accuracy_score(y_test,y_pred_rf)\n",
    "print('RandomForest')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_rf))\n",
    "\n",
    "#for precision\n",
    "precision_rf=metrics.precision_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_rf))\n",
    "\n",
    "#for recall\n",
    "recall_rf=metrics.recall_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_rf))\n",
    "\n",
    "#for f-score\n",
    "fscore_rf=metrics.f1_score(y_test,y_pred_rf,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11bac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "accuracy_score1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with LogisticRegression\n",
    "classifier7=LogisticRegression()\n",
    "classifier7.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_lr=classifier7.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_lr)\n",
    "accuracy_score_lr=metrics.accuracy_score(y_test,y_pred_lr)\n",
    "print('LogisticRegression')\n",
    "print(\"accuracy_score{:.4f}\".format(accuracy_score_lr))\n",
    "\n",
    "#for precision\n",
    "precision_lr=metrics.precision_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_lr))\n",
    "\n",
    "#for recall\n",
    "recall_lr=metrics.recall_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_lr))\n",
    "\n",
    "#for f-score\n",
    "fscore_lr=metrics.f1_score(y_test,y_pred_lr,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "accuracy_score=1.0000\n",
      "precision_score=1.0000\n",
      "recall_score=1.0000\n",
      "f-score=1.0000\n"
     ]
    }
   ],
   "source": [
    "#fitting model with AdaBoostClassifier\n",
    "classifier8=AdaBoostClassifier()\n",
    "classifier8.fit(X_train2,y_train2)\n",
    "\n",
    "#predicting output\n",
    "y_pred_AB=classifier8.predict(X_test)\n",
    "\n",
    "#accuracy measurement\n",
    "cm=metrics.confusion_matrix(y_test,y_pred_AB)\n",
    "accuracy_score_AB=metrics.accuracy_score(y_test,y_pred_AB)\n",
    "print('GradientBoosting')\n",
    "print(\"accuracy_score={:.4f}\".format(accuracy_score_AB))\n",
    "\n",
    "#for precision\n",
    "precision_AB=metrics.precision_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"precision_score={:.4f}\".format(precision_AB))\n",
    "\n",
    "#for recall\n",
    "recall_AB=metrics.recall_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"recall_score={:.4f}\".format(recall_AB))\n",
    "\n",
    "#for f-score\n",
    "fscore_AB=metrics.f1_score(y_test,y_pred_AB,average='weighted')\n",
    "print(\"f-score={:.4f}\".format(fscore_AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0ab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising plots\n",
    "accuracy=np.array([accuracy_score_mlp,accuracy_score_nb,accuracy_score_DT,accuracy_score_svm,accuracy_score_knn,accuracy_score_rf,accuracy_score_lr,accuracy_score_AB])\n",
    "precision=np.array([precision_mlp,precision_nb,precision_DT,precision_svm,precision_knn,precision_rf,precision_lr,precision_AB])\n",
    "recall=np.array([recall_mlp,recall_nb,recall_DT,recall_svm,recall_knn,recall_rf,recall_lr,recall_AB])\n",
    "fscore=np.array([fscore_knn,fscore_nb,fscore_DT,fscore_svm,fscore_knn,fscore_rf,fscore_lr,fscore_AB])\n",
    "x=np.arange(len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfe5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "bar_width=0.15\n",
    "plt.bar(x,accuracy,width=bar_width,color='purple',zorder=2)\n",
    "plt.bar(x+bar_width,precision,width=bar_width,color='orange',zorder=2)\n",
    "plt.bar(x+bar_width*2,recall,width=bar_width,color='red',zorder=2)\n",
    "plt.bar(x+bar_width*3,fscore,width=bar_width,color='green',zorder=2)\n",
    "\n",
    "\n",
    "#for labeling part\n",
    "plt.xticks(x+bar_width*1.5,['MLP','NB',\"DT\",\"SVC\",\"KNN\",\"RF\",\"LR\",\"AB\"])\n",
    "plt.title('Results on Jm1 dataset without feature selection method')\n",
    "\n",
    "#for making patches\n",
    "green=mpatches.Patch(color='purple',label='accuracy')\n",
    "orange=mpatches.Patch(color='orange',label='precision')\n",
    "red=mpatches.Patch(color='red',label='recall')\n",
    "purple=mpatches.Patch(color='green',label='fscore')\n",
    "plt.legend(handles=[purple,orange,red,green])\n",
    "plt.ylim(0,1.5)\n",
    "\n",
    "#grid\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
